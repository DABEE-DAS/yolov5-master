import sys
import streamlit as st
import torch
import numpy as np
import os
import cv2
import pathlib
from PIL import Image
from pathlib import Path
import torchvision.ops as ops
import matplotlib.pyplot as plt

# Windows í™˜ê²½ì—ì„œ 'PosixPath' ëŒ€ì‹  'WindowsPath'ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •
if os.name == 'nt':
    pathlib.PosixPath = pathlib.WindowsPath

# YOLOv5 ê²½ë¡œ ì¶”ê°€
YOLOV5_PATH = str("./")
sys.path.append(YOLOV5_PATH)

# YOLOv5ì—ì„œ í•„ìš”í•œ ëª¨ë“ˆ ë¶ˆëŸ¬ì˜¤ê¸°
from models.experimental import attempt_load
from models.common import DetectMultiBackend
from utils.general import non_max_suppression, scale_boxes
from utils.torch_utils import select_device
from utils.augmentations import letterbox  # YOLOv5 ë¦¬ì‚¬ì´ì§• ë°©ì‹ ì‚¬ìš©

# âœ… ì‚¬ìš©í•  YOLOv5 ëª¨ë¸ 5ê°œ ì„¤ì • (K-Fold ëª¨ë¸)
MODEL_PATHS = [
    "./runs/train/fold_1/weights/best_fold1.pt",
    "./runs/train/fold_2/weights/best_fold2.pt",
    "./runs/train/fold_3/weights/best_fold3.pt",
    "./runs/train/fold_4/weights/best_fold4.pt",
    "./runs/train/fold_5/weights/best_fold5.pt",
]

# âœ… ê°œë³„ YOLOv5 ëª¨ë¸ ì¶”ê°€
SINGLE_MODEL_PATH = "./runs/train/exp/weights/best.pt"

# âœ… YOLOv5 ëª¨ë¸ 5ê°œ ë¡œë“œ (K-Fold)
@st.cache_resource
def load_models():
    return [attempt_load(path) for path in MODEL_PATHS]

# âœ… ê°œë³„ YOLOv5 ëª¨ë¸ ë¡œë“œ
@st.cache_resource
def load_single_model():
    device = select_device('cpu')
    return DetectMultiBackend(SINGLE_MODEL_PATH, device=device, dnn=False)

# Streamlit UI - ëª¨ë¸ ì„ íƒ
st.title("YOLOv5 K-Fold ì•™ìƒë¸” & ê°œë³„ ëª¨ë¸ Object Detection")
st.write("ğŸ“Œ YOLOv5 5ê°œì˜ K-Fold ëª¨ë¸ê³¼ ê°œë³„ ëª¨ë¸ì„ ë¹„êµí•˜ì—¬ ê°ì²´ íƒì§€")

# ëª¨ë¸ ì„ íƒ ë“œë¡­ë‹¤ìš´ ì¶”ê°€
model_type = st.radio("ì‚¬ìš©í•  ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”:", ["K-Fold ì•™ìƒë¸”", "ë‹¨ì¼ YOLOv5 ëª¨ë¸"])

if model_type == "K-Fold ì•™ìƒë¸”":
    models = load_models()
    st.write("âœ… YOLOv5 K-Fold ì•™ìƒë¸” ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
else:
    models = [load_single_model()]  # ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ìœ ì§€
    st.write("âœ… ë‹¨ì¼ YOLOv5 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")

# âœ… YOLOv5 í´ë˜ìŠ¤ ì´ë¦„ ì„¤ì •
CLASS_NAMES = ["extruded", "crack", "cutting", "side_stamped"]

# âœ… ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocess_image(image, final_size=(500, 500), margin=20):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    _, binary = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY_INV)
    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    if contours:
        contour = max(contours, key=cv2.contourArea)
        x, y, w, h = cv2.boundingRect(contour)
        height, width, _ = image.shape
        x_new = max(0, x - margin)
        y_new = max(0, y - margin)
        x_end = min(width, x + w + margin)
        y_end = min(height, y + h + margin)

        cropped = image[y_new:y_end, x_new:x_end]
        resized_image = cv2.resize(cropped, final_size, interpolation=cv2.INTER_LINEAR)
        return resized_image
    else:
        return cv2.resize(image, final_size, interpolation=cv2.INTER_LINEAR)

# âœ… YOLOv5 ì…ë ¥ ë³€í™˜ í•¨ìˆ˜
def prepare_image(image, img_size=640):
    img_resized, ratio, pad = letterbox(image, new_shape=img_size, auto=True)
    img_resized = img_resized[:, :, ::-1].transpose(2, 0, 1)  # HWC â†’ CHW
    img_resized = np.ascontiguousarray(img_resized)
    img_tensor = torch.from_numpy(img_resized).float() / 255.0
    img_tensor = img_tensor.unsqueeze(0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
    return image, img_tensor, ratio, pad

# âœ… YOLOv5 ëª¨ë¸ ì˜ˆì¸¡ í•¨ìˆ˜
def get_predictions(models, img, conf_thres=0.3, iou_thres=0.5):
    all_boxes, all_scores, all_labels = [], [], []

    for model in models:
        with torch.no_grad():
            pred = model(img)[0]
        pred = non_max_suppression(pred, conf_thres, iou_thres)[0]

        if pred is not None and len(pred) > 0:
            all_boxes.append(pred[:, :4])
            all_scores.append(pred[:, 4])
            all_labels.append(pred[:, 5])

    if len(all_boxes) == 0:
        return [], [], []

    all_boxes = torch.cat(all_boxes, dim=0)
    all_scores = torch.cat(all_scores, dim=0)
    all_labels = torch.cat(all_labels, dim=0)

    return all_boxes, all_scores, all_labels

# âœ… NMS ì•™ìƒë¸” í•¨ìˆ˜
def ensemble_nms(boxes, scores, labels, iou_thres=0.5):
    keep_indices = ops.nms(boxes, scores, iou_thres)
    return boxes[keep_indices].cpu().numpy(), scores[keep_indices].cpu().numpy(), labels[keep_indices].cpu().numpy()

# ì´ë¯¸ì§€ ì—…ë¡œë“œ
uploaded_files = st.file_uploader("ğŸ“‚ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["jpg", "png", "jpeg"], accept_multiple_files=True)

# ì„¸ì…˜ ìƒíƒœì—ì„œ í˜„ì¬ ì´ë¯¸ì§€ ì¸ë±ìŠ¤ ì €ì¥ (ì´ˆê¸°ê°’: 0)
if "image_index" not in st.session_state:
    st.session_state.image_index = 0

if uploaded_files:
    total_images = len(uploaded_files)

    if total_images > 1:
        selected_index = st.slider("ì´ë¯¸ì§€ ì„ íƒ", 0, total_images - 1, st.session_state.image_index)
        if selected_index != st.session_state.image_index:
            st.session_state.image_index = selected_index
            st.rerun()

    current_index = st.session_state.image_index
    uploaded_file = uploaded_files[current_index]
    image = Image.open(uploaded_file)
    image = np.array(image)

    # âœ… ì „ì²˜ë¦¬ ì ìš©
    processed_image = preprocess_image(image)

    # âœ… ëª¨ë¸ ì˜ˆì¸¡ê°’ ì–»ê¸°
    _, img_tensor, ratio, pad = prepare_image(processed_image)
    boxes, scores, labels = get_predictions(models, img_tensor)

    # âœ… NMS ì ìš©
    nms_boxes, nms_scores, nms_labels = ensemble_nms(boxes, scores, labels)

    # âœ… ë°”ìš´ë”© ë°•ìŠ¤ ìœ„ì¹˜ ë³€í™˜ ì ìš©
    nms_boxes = scale_boxes(img_tensor.shape[2:], torch.tensor(nms_boxes), processed_image.shape).round().numpy()

    # âœ… ê²°ê³¼ í‘œì‹œ
    for box, score, label in zip(nms_boxes, nms_scores, nms_labels):
        x1, y1, x2, y2 = map(int, box)
        class_name = CLASS_NAMES[int(label)] if int(label) < len(CLASS_NAMES) else f"Class {int(label)}"
        cv2.rectangle(processed_image, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(processed_image, f"{class_name}: {score:.2f}", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    st.image(processed_image, caption=f"Detection Results - {uploaded_file.name}", use_column_width=True)

    # **"ì´ì „" ë° "ë‹¤ìŒ" ë²„íŠ¼ ì¶”ê°€**
    col1, col2 = st.columns([1, 1])
    with col1:
        if st.session_state.image_index > 0:
            if st.button("ì´ì „ ì´ë¯¸ì§€"):
                st.session_state.image_index -= 1
                st.rerun()
    with col2:
        if st.session_state.image_index < total_images - 1:
            if st.button("ë‹¤ìŒ ì´ë¯¸ì§€"):
                st.session_state.image_index += 1
                st.rerun()


